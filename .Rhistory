X_bf_new2 <- X[1:t_tild]
X_af_new2 <- X[(t_tild+1):N]
lag_p1_new2 <- as.vector(VARselect(X_bf_new2)$selection[1])
lag_p2_new2 <- as.vector(VARselect(X_af_new2)$selection[1])
lag_new2_max <- max(lag_p1_new2,lag_p2_new2)
phi1_new2 <- yw(X_bf_new2,lag_p1_new2)$phi
phi2_new2 <- yw(X_af_new2,lag_p2_new2)$phi
if(lag_p1_new2 < lag_p2_new2){
phi1_new2 <- c(phi1_new2,rep(0,lag_p2_new2-lag_p1_new2))
}
if(lag_p1_new2 > lag_p2_new2){
phi2_new2 <- c(phi2_new2,rep(0,lag_p1_new2-lag_p2_new2))
}
Z_bf_new2 <- matrix(0,nrow=t_tild,ncol=lag_new2_max)
for(t in 1:t_tild){
for(j in 1:lag_new2_max){
Z_bf_new2[t,j] <- ifelse(j<t,X_bf_new2[t-j],0)
}
}
Z_af_new2 <- matrix(0,nrow=N-t_tild,ncol=lag_new2_max)
for(t in 1:N-t_tild){
for(j in 1:lag_new2_max){
Z_af_new2[t,j] <- ifelse(j<t,X_af_new2[t-j],0)
}
}
# covariance matrices
SIGMA1 <- cov(Z_bf_new2)
SIGMA2 <- cov(Z_af_new2)
# jump size (xi2)
eta_star <- phi1_new2 - phi2_new2
xi2_bf <- sqrt(sum(eta_star^2))
xi2_af <- sqrt(sum(eta_star^2))
# estimation of sigma's from limits
sigma1_2 <- as.vector(xi2_bf^(-2)*(matrix(eta_star,nrow=1)%*%SIGMA1%*%t(matrix(eta_star,nrow=1))))
sigma2_2 <- as.vector(xi2_af^(-2)*(matrix(eta_star,nrow=1)%*%SIGMA2%*%t(matrix(eta_star,nrow=1))))
e_bf <- t(X_bf_new2 - Z_bf_new2%*%phi1_new2)
e_af <- t(X_af_new2 - Z_af_new2%*%phi2_new2)
dd_1 <- as.vector((t(Z_bf_new2%*%eta_star)*e_bf))
dd_1 <- dd_1[(lag_new2_max+1):length(dd_1)]
dd_2 <- as.vector((t(Z_af_new2%*%eta_star)*e_af))
dd_2 <- dd_2[(lag_new2_max+1):length(dd_2)]
sigma1_star_2 <- xi2_bf^(-2)*(var(dd_1))
sigma2_star_2 <- xi2_af^(-2)*(var(dd_2))
# confidence interval
L_hat <- as.vector((sigma1_2^2)*(1/sigma1_star_2)*(xi2_bf^2))
# following parameters come from Bai's paper
phi_G <- 1*sigma2_star_2/sigma1_star_2
xi_G <- as.vector(sigma2_2/sigma1_2)
a_n <- 0.5*(xi_G/phi_G)*(1+(xi_G/phi_G))
b_n <- 0.5+(xi_G/phi_G)
c_n <- (phi_G*(phi_G+2*xi_G))/(xi_G*(phi_G+xi_G))
d_n <- (phi_G+2*xi_G)^2/((phi_G+xi_G)*xi_G)
a_p <- (phi_G+xi_G)/2
b_p <- (2*phi_G+xi_G)/(2*sqrt(phi_G))
c_p <- (xi_G*(2*phi_G+xi_G))/((phi_G+xi_G)*phi_G)
d_p <- (2*phi_G+xi_G)^2/((phi_G+xi_G)*phi_G)
Q_L90 <- quantile_low(a_n,b_n,c_n,d_n,xi_G,phi_G,0.05)
Q_U90 <- quantile_up(a_p,b_p,c_p,d_p,xi_G,phi_G,0.95)
L90 <- t_tild-floor(Q_U90/L_hat)-1
U90 <- t_tild-floor(Q_L90/L_hat)+1
Q_L95 <- quantile_low(a_n,b_n,c_n,d_n,xi_G,phi_G,0.025)
Q_U95 <- quantile_up(a_p,b_p,c_p,d_p,xi_G,phi_G,0.975)
L95 <- t_tild-floor(Q_U95/L_hat)-1
U95 <- t_tild-floor(Q_L95/L_hat)+1
Q_L99 <- quantile_low(a_n,b_n,c_n,d_n,xi_G,phi_G,0.005)
Q_U99 <- quantile_up(a_p,b_p,c_p,d_p,xi_G,phi_G,0.995)
L99 <- t_tild-floor(Q_U99/L_hat)-1
U99 <- t_tild-floor(Q_L99/L_hat)+1
cat("End rep", date(),"\n")
return( cbind(t_hat,t_tild,L90,U90,L95,U95,L99,U99) )  #Final Output of Loop
}
## Replicate 50 sample:
R <- 50
many.reps <- replicate(n=R,one.rep()); dim(many.reps)
many.reps <- cbind(many.reps[1,1,],many.reps[1,2,],many.reps[1,3,],many.reps[1,4,],
many.reps[1,5,],many.reps[1,6,],many.reps[1,7,],many.reps[1,8,])
## criteria of evaluations:
Bias_t.hat <- abs(mean(many.reps[,1]-truth))
Bias_t.tild <- abs(mean(many.reps[,2]-truth))
cbind(Bias_t.hat,Bias_t.tild)
RMSE_t.hat <- sqrt(mean((many.reps[,1]-truth)^2))
RMSE_t.tild <- sqrt(mean((many.reps[,2]-truth)^2))
cbind(RMSE_t.hat,RMSE_t.tild)
Indicator_t.tild90 <- rep(NA,R)
for(i in 1:R){
Indicator_t.tild90[i] <- as.integer(truth >= many.reps[i,3] && truth <= many.reps[i,4])
}
coverage_t.tild90 <- mean(Indicator_t.tild90)
coverage_t.tild90
Indicator_t.tild95 <- rep(NA,R)
for(i in 1:R){
Indicator_t.tild95[i] <- as.integer(truth >= many.reps[i,5] && truth <= many.reps[i,6])
}
coverage_t.tild95 <- mean(Indicator_t.tild95)
coverage_t.tild95
Indicator_t.tild99 <- rep(NA,R)
for(i in 1:R){
Indicator_t.tild99[i] <- as.integer(truth >= many.reps[i,7] && truth <= many.reps[i,8])
}
coverage_t.tild99 <- mean(Indicator_t.tild99)
coverage_t.tild99
# change point time
N <- 800 # time series length N={500, 1000, 1500, 2000}
truth <- floor(N/2)
set.seed(123456)
## Intro. Repetition Loop
one.rep <- function(){
cat("start rep",date(),"\n")
w <- 200
# noise
epsilon <- rnorm(N+2*w,0,1)
# model AR(1)
X_bf <- rep(0,truth+w)
ar_par <- 0.6
for(t in 2:(truth+w)){
X_bf[1] <- epsilon[1]
X_bf[t] <- ar_par*X_bf[t-1]+epsilon[t]
}
X_bf <- X_bf[(w+1):(truth+w)]
# model AR(1)
X_af <- rep(0,N-truth+w)
ma_par <- 0.4
for(t in 2:(N-truth+w)){
X_af[1] <- epsilon[truth+1]
X_af[t] <- ma_par*X_af[t-1]+epsilon[truth+t]
}
X_af <- X_af[(w+1):(N-truth+w)]
# # model MA(1)
# X_af <- rep(0,N-truth+w)
# ma_par <- 0.1
# for(t in 2:(N-truth+w)){
#   X_af[1] <- epsilon[truth+1]
#   X_af[t] <- epsilon[truth+t]+ma_par*epsilon[truth+t-1]
# }
#
# X_af <- X_af[(w+1):(N-truth+w)]
X <- c(X_bf,X_af) # entire of time-series
# plot(X, type = 'l')
# lag selection
lag_p1 <- as.vector(VARselect(X_bf)$selection[1])
lag_p2 <- as.vector(VARselect(X_af)$selection[1])
# Estimating phi's using the Yule-Walker method
phi1 <- yw(X_bf,lag_p1)$phi
phi2 <- yw(X_af,lag_p2)$phi
# objective function
dist <- 20
tau <- (dist):(N-dist)
M <- length(tau)
L <- rep(0,M)
X_bf_loop <- foreach(i=1:M) %do% X[1:tau[i]]
X_af_loop <- foreach(i=1:M) %do% X[(tau[i]+1):N]
lag_p1_loop <- foreach(i=1:M) %do% as.vector(VARselect(X_bf_loop[[i]])$selection[1])
lag_p2_loop <- foreach(i=1:M) %do% as.vector(VARselect(X_af_loop[[i]])$selection[1])
#phi1_loop <- sapply(1:M,function(i){yw(X_bf_loop[[i]],lag_p1_loop[[i]])$phi})
#phi2_loop <- sapply(1:M,function(i){yw(X_af_loop[[i]],lag_p2_loop[[i]])$phi})
gamma.hat <- foreach(i=1:M) %do% sample.acf(X_bf_loop[[i]])$gamma.hat
gamma.0.hat <- foreach(i=1:M) %do% gamma.hat[[i]][1]
gamma.n.hat <- foreach(i=1:M) %do% gamma.hat[[i]][-1]
DL.1step.out <- foreach(i=1:M) %do% DL.1step(X_bf_loop[[i]]-mean(X_bf_loop[[i]]),gamma.0.hat[[i]],gamma.n.hat[[i]])
phi1_loop <- sapply(1:M,function(i){DL.1step.out[[i]]$Phi[1+lag_p1_loop[[i]],lag_p1_loop[[i]]:1]})
gamma.hat <- foreach(i=1:M) %do% sample.acf(X_af_loop[[i]])$gamma.hat
gamma.0.hat <- foreach(i=1:M) %do% gamma.hat[[i]][1]
gamma.n.hat <- foreach(i=1:M) %do% gamma.hat[[i]][-1]
DL.1step.out <- foreach(i=1:M) %do% DL.1step(X_af_loop[[i]]-mean(X_af_loop[[i]]),gamma.0.hat[[i]],gamma.n.hat[[i]])
phi2_loop <- sapply(1:M,function(i){DL.1step.out[[i]]$Phi[1+lag_p2_loop[[i]],lag_p2_loop[[i]]:1]})
for(i in 1:M){
Z_bf_loop <- matrix(0,nrow=tau[i],ncol=lag_p1_loop[[i]])
for(t in 1:tau[i]){
for(j in 1:lag_p1_loop[[i]]){
Z_bf_loop[t,j] <- ifelse(j<t,X_bf_loop[[i]][t-j],0)
}
}
Z_af_loop <- matrix(0,nrow=N-tau[i],ncol=lag_p2_loop[[i]])
for(t in 1:N-tau[i]){
for(j in 1:lag_p2_loop[[i]]){
Z_af_loop[t,j] <- ifelse(j<t,X_af_loop[[i]][t-j],0)
}
}
L[i] <- sum((X_bf_loop[[i]]-Z_bf_loop%*%matrix(phi1_loop[[i]],ncol=1))^2)+
sum((X_af_loop[[i]]-Z_af_loop%*%matrix(phi2_loop[[i]],ncol=1))^2)
}
# near optimal estimator
Min_data <- data.frame(cbind(tau,L))
t_hat <- Min_data$tau[which(Min_data$L==min(Min_data$L))]
# plot(Min_data$tau,Min_data$L)
# refitting process
X_bf_new <- X[1:t_hat]
X_af_new <- X[(t_hat+1):N]
lag_p1_new <- as.vector(VARselect(X_bf_new)$selection[1])
lag_p2_new <- as.vector(VARselect(X_af_new)$selection[1])
lag_new_max <- max(lag_p1_new,lag_p2_new)
phi1_new <- yw(X_bf_new,lag_p1_new)$phi
phi2_new <- yw(X_af_new,lag_p2_new)$phi
if(lag_p1_new < lag_p2_new){
phi1_new <- c(phi1_new,rep(0,lag_p2_new-lag_p1_new))
}
if(lag_p1_new > lag_p2_new){
phi2_new <- c(phi2_new,rep(0,lag_p1_new-lag_p2_new))
}
# new objective function (without changing {lag_p1_new,lag_p2_new,phi1_new,phi2_new})
dist <- 20
tau2 <- (dist):(N-dist)
M2 <- length(tau2)
Q <- rep(0,M2)
for(i in 1:M2){
X_bf_loop2 <- X[1:tau2[i]]
X_af_loop2 <- X[(tau2[i]+1):N]
Z_bf_loop2 <- matrix(0,nrow=tau2[i],ncol=lag_new_max)
for(t in 1:tau2[i]){
for(j in 1:lag_new_max){
Z_bf_loop2[t,j] <- ifelse(j<t,X_bf_loop2[t-j],0)
}
}
Z_af_loop2 <- matrix(0,nrow=N-tau2[i],ncol=lag_new_max)
for(t in 1:N-tau2[i]){
for(j in 1:lag_new_max){
Z_af_loop2[t,j] <- ifelse(j<t,X_af_loop2[t-j],0)
}
}
Q[i] <- sum((X_bf_loop2-Z_bf_loop2%*%matrix(phi1_new,ncol=1))^2)/(N-2*lag_new_max+1)+
sum((X_af_loop2-Z_af_loop2%*%matrix(phi2_new,ncol=1))^2)/(N-2*lag_new_max+1)
}
# optimal estimator
Min_data2 <- data.frame(cbind(tau2,Q))
t_tild <- Min_data2$tau2[which(Min_data2$Q==min(Min_data2$Q))]
# updating all the elements based on t_tild
X_bf_new2 <- X[1:t_tild]
X_af_new2 <- X[(t_tild+1):N]
lag_p1_new2 <- as.vector(VARselect(X_bf_new2)$selection[1])
lag_p2_new2 <- as.vector(VARselect(X_af_new2)$selection[1])
lag_new2_max <- max(lag_p1_new2,lag_p2_new2)
phi1_new2 <- yw(X_bf_new2,lag_p1_new2)$phi
phi2_new2 <- yw(X_af_new2,lag_p2_new2)$phi
if(lag_p1_new2 < lag_p2_new2){
phi1_new2 <- c(phi1_new2,rep(0,lag_p2_new2-lag_p1_new2))
}
if(lag_p1_new2 > lag_p2_new2){
phi2_new2 <- c(phi2_new2,rep(0,lag_p1_new2-lag_p2_new2))
}
Z_bf_new2 <- matrix(0,nrow=t_tild,ncol=lag_new2_max)
for(t in 1:t_tild){
for(j in 1:lag_new2_max){
Z_bf_new2[t,j] <- ifelse(j<t,X_bf_new2[t-j],0)
}
}
Z_af_new2 <- matrix(0,nrow=N-t_tild,ncol=lag_new2_max)
for(t in 1:N-t_tild){
for(j in 1:lag_new2_max){
Z_af_new2[t,j] <- ifelse(j<t,X_af_new2[t-j],0)
}
}
# covariance matrices
SIGMA1 <- cov(Z_bf_new2)
SIGMA2 <- cov(Z_af_new2)
# jump size (xi2)
eta_star <- phi1_new2 - phi2_new2
xi2_bf <- sqrt(sum(eta_star^2))
xi2_af <- sqrt(sum(eta_star^2))
# estimation of sigma's from limits
sigma1_2 <- as.vector(xi2_bf^(-2)*(matrix(eta_star,nrow=1)%*%SIGMA1%*%t(matrix(eta_star,nrow=1))))
sigma2_2 <- as.vector(xi2_af^(-2)*(matrix(eta_star,nrow=1)%*%SIGMA2%*%t(matrix(eta_star,nrow=1))))
e_bf <- t(X_bf_new2 - Z_bf_new2%*%phi1_new2)
e_af <- t(X_af_new2 - Z_af_new2%*%phi2_new2)
dd_1 <- as.vector((t(Z_bf_new2%*%eta_star)*e_bf))
dd_1 <- dd_1[(lag_new2_max+1):length(dd_1)]
dd_2 <- as.vector((t(Z_af_new2%*%eta_star)*e_af))
dd_2 <- dd_2[(lag_new2_max+1):length(dd_2)]
sigma1_star_2 <- xi2_bf^(-2)*(var(dd_1))
sigma2_star_2 <- xi2_af^(-2)*(var(dd_2))
# confidence interval
L_hat <- as.vector((sigma1_2^2)*(1/sigma1_star_2)*(xi2_bf^2))
# following parameters come from Bai's paper
phi_G <- 1*sigma2_star_2/sigma1_star_2
xi_G <- as.vector(sigma2_2/sigma1_2)
a_n <- 0.5*(xi_G/phi_G)*(1+(xi_G/phi_G))
b_n <- 0.5+(xi_G/phi_G)
c_n <- (phi_G*(phi_G+2*xi_G))/(xi_G*(phi_G+xi_G))
d_n <- (phi_G+2*xi_G)^2/((phi_G+xi_G)*xi_G)
a_p <- (phi_G+xi_G)/2
b_p <- (2*phi_G+xi_G)/(2*sqrt(phi_G))
c_p <- (xi_G*(2*phi_G+xi_G))/((phi_G+xi_G)*phi_G)
d_p <- (2*phi_G+xi_G)^2/((phi_G+xi_G)*phi_G)
Q_L90 <- quantile_low(a_n,b_n,c_n,d_n,xi_G,phi_G,0.05)
Q_U90 <- quantile_up(a_p,b_p,c_p,d_p,xi_G,phi_G,0.95)
L90 <- t_tild-floor(Q_U90/L_hat)-1
U90 <- t_tild-floor(Q_L90/L_hat)+1
Q_L95 <- quantile_low(a_n,b_n,c_n,d_n,xi_G,phi_G,0.025)
Q_U95 <- quantile_up(a_p,b_p,c_p,d_p,xi_G,phi_G,0.975)
L95 <- t_tild-floor(Q_U95/L_hat)-1
U95 <- t_tild-floor(Q_L95/L_hat)+1
Q_L99 <- quantile_low(a_n,b_n,c_n,d_n,xi_G,phi_G,0.005)
Q_U99 <- quantile_up(a_p,b_p,c_p,d_p,xi_G,phi_G,0.995)
L99 <- t_tild-floor(Q_U99/L_hat)-1
U99 <- t_tild-floor(Q_L99/L_hat)+1
cat("End rep", date(),"\n")
return( cbind(t_hat,t_tild,L90,U90,L95,U95,L99,U99) )  #Final Output of Loop
}
## Replicate 50 sample:
R <- 50
many.reps <- replicate(n=R,one.rep()); dim(many.reps)
many.reps <- cbind(many.reps[1,1,],many.reps[1,2,],many.reps[1,3,],many.reps[1,4,],
many.reps[1,5,],many.reps[1,6,],many.reps[1,7,],many.reps[1,8,])
## criteria of evaluations:
Bias_t.hat <- abs(mean(many.reps[,1]-truth))
Bias_t.tild <- abs(mean(many.reps[,2]-truth))
cbind(Bias_t.hat,Bias_t.tild)
RMSE_t.hat <- sqrt(mean((many.reps[,1]-truth)^2))
RMSE_t.tild <- sqrt(mean((many.reps[,2]-truth)^2))
cbind(RMSE_t.hat,RMSE_t.tild)
Indicator_t.tild90 <- rep(NA,R)
for(i in 1:R){
Indicator_t.tild90[i] <- as.integer(truth >= many.reps[i,3] && truth <= many.reps[i,4])
}
coverage_t.tild90 <- mean(Indicator_t.tild90)
coverage_t.tild90
Indicator_t.tild95 <- rep(NA,R)
for(i in 1:R){
Indicator_t.tild95[i] <- as.integer(truth >= many.reps[i,5] && truth <= many.reps[i,6])
}
coverage_t.tild95 <- mean(Indicator_t.tild95)
coverage_t.tild95
Indicator_t.tild99 <- rep(NA,R)
for(i in 1:R){
Indicator_t.tild99[i] <- as.integer(truth >= many.reps[i,7] && truth <= many.reps[i,8])
}
coverage_t.tild99 <- mean(Indicator_t.tild99)
coverage_t.tild99
mHealth_subject1 <- read.delim("C:/Users/Abi/Downloads/mhealth+dataset/MHEALTHDATASET/mHealth_subject1.log", header=FALSE)
View(mHealth_subject1)
setwd("C:/Users/Abi/UFL Dropbox/Abolfazl Safikhani/Mingliang/Low rank plus sparse/Nips 24/code (1)")
library(magick)
library(plot.matrix)
source(func.R)
source("func.R")
#---------------------------------------------------------------------------------------------------------------------
#process data
resize <- function(x1,y1,x2,y2,mat){
i1 <- x2/x1; i2 <- y2/y1
mat_new <- matrix(0,x1,y1)
for(i in 1:x1){
for(j in 1:y1){
mat_new[i,j] <- sum(mat[(1+(i-1)*i1):(i*i1),(1+(j-1)*i2):(j*i2)])/(i1*i2)
}
}
return(mat_new)
}
path <- 'JPEGS/Meet_WalkTogether'
for(i in 2000:2826){
name <- paste(as.character(i),sep="",".jpg")
filename <- paste(path, sep = "", name)
img_temp <- image_read(filename)
img_gray <-image_convert(img_temp, type = 'grayscale')
mat0 <- image_data(img_gray, 'rgba')
mat <- as.integer(mat0)
mat_new <- as.matrix(mat[1:288,1:384,1],288,384)
mat_new <- resize(24,32,288,384, mat_new)/256
mat_vec <- c(mat_new)
frame <- rbind(frame, mat_vec)
}
i
name <- paste(as.character(i),sep="",".jpg")
filename <- paste(path, sep = "", name)
img_temp <- image_read(filename)
img_gray <-image_convert(img_temp, type = 'grayscale')
mat0 <- image_data(img_gray, 'rgba')
mat <- as.integer(mat0)
mat_new <- as.matrix(mat[1:288,1:384,1],288,384)
mat_new <- resize(24,32,288,384, mat_new)/256
mat_vec <- c(mat_new)
frame <- rbind(frame, mat_vec)
frame <- c()
frame <- rbind(frame, mat_vec)
frame <- c()
path <- 'JPEGS/Meet_WalkTogether'
for(i in 2000:2826){
name <- paste(as.character(i),sep="",".jpg")
filename <- paste(path, sep = "", name)
img_temp <- image_read(filename)
img_gray <-image_convert(img_temp, type = 'grayscale')
mat0 <- image_data(img_gray, 'rgba')
mat <- as.integer(mat0)
mat_new <- as.matrix(mat[1:288,1:384,1],288,384)
mat_new <- resize(24,32,288,384, mat_new)/256
mat_vec <- c(mat_new)
frame <- rbind(frame, mat_vec)
}
#---------------------------------------------------------------------------------------------------------------------
#save and read processed data
write.matrix(frame,"walk.txt",sep = "\t")
#---------------------------------------------------------------------------------------------------------------------
#first step:
#estimate L and S_1,...,S_K
group <- c(1,116,174,232,290,348,406, 464,522,580,638,696)#starting point of each segment
K <- 12 #number of segment
p<- 768; N <- 826
X <- frame[1:826,]
Y <- frame[2:827,]
tau1 <- 0.01; tau2 <- 0.1
lambda <- tau1*sqrt(60*log(768))
mu <- tau2*sqrt(826*768)
niter <- 100
out <- fista.LpS(X, Y, lambda, mu, group, K, niter, backtracking = TRUE)
lr.comp <- out$lr.comp #low rank matrix estimator
#-------------------------------------------------------------------------------------------------------------
#second step: transfer learning for sparse matrix
ls_S_tran <- list();ls_S_selectA <- list() ;ls_S_lasso <- list(); tau <- 0.01
group <- c(group, N+1); ls_select_index <- matrix(0,K,K)
for(i in 1:K){
n1 <- group[i+1]-group[i]; n2 <- N - n1
lambda1 = sqrt(tau*log(p)/n1); lambda2 = sqrt(tau*log(p)/N)
target_index <- group[i]:(group[i+1]-1)
X0 <- X[target_index,]; XA <- X[-target_index,]
Y0 <- Y[target_index,]; YA <- Y[-target_index,]
X0_train <- X0[1:floor(2/3*n1),]; X0_test <- X0[(1+floor(2/3*n1)) : n1,]
Y0_train <- Y0[1:floor(2/3*n1),]; Y0_test <- Y0[(1+floor(2/3*n1)) : n1,]
X_temp <- rbind(X0_train, XA); Y_temp <- rbind(Y0_train, YA)
#lasso-------------------------------------------------------------------------------------------------------
ls_S_lasso[[i]] <- lasso(X0_train, Y0_train - X0_train%*%lr.comp, p ,1, lambda1)
#transfer learning with all data-----------------------------------------------------------------------------
ls_S_tran[[i]] <- tran_learn(X_temp, Y_temp - X_temp%*%lr.comp, 0.1*lambda1,lambda2, p, 1, floor(2/3*n1), n2)
#transfer learning with select info set---------------------------------------------------------------------------
#step 1
n <- floor(2/3*n1)
sp = floor(n/2)
lambda1_test = sqrt(tau*log(p)/sp)
beta_la_1 = lasso(X0_train[1:sp,], Y0_train[1:sp,] - X0_train[1:sp,]%*%lr.comp, p ,d, lambda1_test)
beta_la_2 = lasso(X0_train[(sp+1):n,], Y0_train[(sp+1):n,] - X0_train[(sp+1):n,]%*%lr.comp, p ,d, lambda1_test)
select_set <- c()
ls_R_k <- c()
aux_group <- (1:K)[-i]
for(l in aux_group){
# X_auxiliary <- XA[((l-1)*(N2-tran)+1):(l*(N2-tran)),]
X_temp <- rbind(X0_train[1:sp,], X[group[l]:(group[l+1]-1),])
Y_temp <- rbind(Y0_train[1:sp,], Y[group[l]:(group[l+1]-1),])
lambda2_test = sqrt(tau*log(p)/(sp+(group[l+1]-(group[l]))))
beta_tran_temp = lasso(X_temp, Y_temp - X_temp%*%lr.comp, p, 1, lambda2_test)
X_test <- X0_train[(sp+1):n,]
Y_test <- Y0_train[(sp+1):n,]
R_k = sum((Y_test - X_test%*%beta_tran_temp - X_test%*%lr.comp)^2) - sum((Y_test - X_test%*%beta_la_1 - X_test%*%lr.comp)^2)
#print(R_k)
R_thre <- abs(sum((Y_test - X_test%*%beta_la_2 - X_test%*%lr.comp)^2) - sum((Y_test - X_test%*%beta_la_1 - X_test%*%lr.comp)^2))
ls_R_k <- c(ls_R_k,R_k)
}
select_set <- which(ls_R_k < 0.1*R_thre)
ls_select_index[i,aux_group[select_set]] <- 1
select_index <- 1:floor(2/3*n1) + group[i] - 1; N <- n1
for(l in aux_group[select_set]){
select_index <- c(select_index, group[l]:(group[l+1]-1) )
N <- N + group[l+1] - group[l]
}
lambda2 = sqrt(tau*log(p)/(N))
#step2:
ls_S_selectA[[i]]  = tran_learn(X[select_index,], Y[select_index,] - X[select_index,]%*%lr.comp , 0.1*lambda1, lambda2, p, 1, floor(2/3*n1), N)
}
#-----------------------------------------------------------------------------------------------------------------------------
#output -- MSE and sd
res_tran <- c(); res_lasso <- c(); res_selectA <- c()
sd_tran <- c(); sd_lasso <- c(); sd_selectA <- c()
for(i in 1:K){
n1 <- group[i+1]-group[i]; n2 <- N - n1
lambda1 = sqrt(tau*log(p)/n1); lambda2 = sqrt(tau*log(p)/N)
target_index <- group[i]:(group[i+1]-1)
X0 <- X[target_index,]; XA <- X[-target_index,]
Y0 <- Y[target_index,]; YA <- Y[-target_index,]
X0_train <- X0[1:floor(2/3*n1),]; X0_test <- X0[(1+floor(2/3*n1)) : n1,]
Y0_train <- Y0[1:floor(2/3*n1),]; Y0_test <- Y0[(1+floor(2/3*n1)) : n1,]
res_tran <- c(res_tran, sum((Y0_test - X0_test%*%lr.comp - X0_test%*%ls_S_tran[[i]])^2))
res_lasso <- c(res_lasso, sum((Y0_test - X0_test%*%lr.comp - X0_test%*%ls_S_lasso[[i]])^2))
res_selectA <- c(res_selectA, sum((Y0_test - X0_test%*%lr.comp - X0_test%*%ls_S_selectA[[i]])^2))
sd_tran <- c(sd_tran, sd((Y0_test - X0_test%*%lr.comp - X0_test%*%ls_S_tran[[i]])))
sd_lasso <- c(sd_lasso, sd((Y0_test - X0_test%*%lr.comp - X0_test%*%ls_S_lasso[[i]])))
sd_selectA <- c(sd_selectA, sd((Y0_test - X0_test%*%lr.comp - X0_test%*%ls_S_selectA[[i]])))
}
#----------------------------------------------------------------------------------------------------------------------------------
#output -- sparse matrix estimator: S_1,...,S_K
#lasso -- ls_S_lasso;  transfer-lasso -- ls_S_tran;
ls_MAT<- list()
for(i in 1:K){
#S_temp <- ls_S_lasso[[i]];
S_temp <- ls_S_selectA[[i]]
ni <- group[i+1] - group[i]
n_sp <- floor((group[i+1] - group[i])*2/3)
target_index <- group[i]:(group[i+1]-1)
X0 <- X[target_index,]; XA <- X[-target_index,]
Y0 <- Y[target_index,]; YA <- Y[-target_index,]
X0_train <- X0[1:n_sp,]; X0_test <- X0[(1+n_sp) : ni,]
Y0_train <- Y0[1:n_sp,]; Y0_test <- Y0[(1+n_sp) : ni,]
Sigma_e_tran = t(Y0_train - X0_train%*%lr.comp - X0_train%*%S_temp)%*%(Y0_train - X0_train%*%lr.comp - X0_train%*%S_temp)/n_sp
fit_tran_debais = lasso_debais(X0_train, Y0_train - X0_train%*%out$lr.comp, Sigma_e_tran, alpha=2 , S_temp, p, 1, mu =2)
matimg_temp <- Mat_img(S_temp, qnorm(0.975)*sqrt(fit_tran_debais$V/n_sp))
index <- which(matimg_temp > 0)
MAT_index <- matrix(0, 768, 768)
MAT_index[index] <- 1
MAT <- matrix(apply(MAT_index,2,sum),24,32)
ls_MAT[[i]] <- MAT
}
#image of sparse matrix
MAX <- 0
for(i in 1:K){
name <- paste("segment",sep="",as.character(i))
filename <- paste(name, sep="",".txt")
#MAT <- as.matrix(read.table(filename,sep = "\t",head = FALSE))
MAX <- max(c(MAX, max(ls_MAT[[i]])))
#MAx <- max(c(MAX, max(MAT)))
}
for(i in 1:K){
name <- paste("segment",sep="",as.character(i))
filename <- paste(name,sep="",".txt")
#MAT <- as.matrix(read.table(filename,sep = "\t",head = FALSE))
MAT <- ls_MAT[[i]]/MAX
image_channel(MAT)
}
